{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "452cdc46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T05:02:00.767985Z",
     "iopub.status.busy": "2021-12-23T05:02:00.766466Z",
     "iopub.status.idle": "2021-12-23T05:02:06.382106Z",
     "shell.execute_reply": "2021-12-23T05:02:06.382560Z",
     "shell.execute_reply.started": "2021-12-23T04:53:44.996846Z"
    },
    "papermill": {
     "duration": 5.629933,
     "end_time": "2021-12-23T05:02:06.382860",
     "exception": false,
     "start_time": "2021-12-23T05:02:00.752927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Making necessary imports\n",
    "# To supress tf warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ff4fc56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T05:02:06.404854Z",
     "iopub.status.busy": "2021-12-23T05:02:06.404221Z",
     "iopub.status.idle": "2021-12-23T05:02:06.428791Z",
     "shell.execute_reply": "2021-12-23T05:02:06.428381Z",
     "shell.execute_reply.started": "2021-12-23T04:51:11.928359Z"
    },
    "papermill": {
     "duration": 0.036996,
     "end_time": "2021-12-23T05:02:06.428903",
     "exception": false,
     "start_time": "2021-12-23T05:02:06.391907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"अब गाह्रो छैन प्रदूषण नाप्न भारतीय पूर्व प्रधानमन्त्रीलाई उपप्रधानमन्त्री निधीले किन भेटे\"\\n\"लाठी लिएका हजारौँ संख्यामा रहेका थारुहरुले र्याली प्रर्दशन गरी राजापुर बजारको दक्षिण चौकमा कोणसभा गरेका थिए\"\\n\"आफूहरुले आफनो स्वाभिमानको लडाइ लडेको उनको भनाई थियो\"\\n\"प्रदर्शनकारीले प्रहरी दमन बन्द गर, कैलाली कञ्चनपुर छाड्दैनौँ , प्रतिगमनकारी होसियार जस्ता नारा लगाएका थिए\"\\n\"भारतको अघोषित नाकाबन्दीका कारण पेट्रोलियम पदार्थको अभाव भएपछि सर्वसाधारणले जोखिमपूर्ण यात्रा गर्नुपर्ने बाध्यता बढेको छ\"\\n\"पेट्रोलियम पद'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../input/nepali65ksentences/data.txt\", \"r\", encoding='utf-8-sig') as f:\n",
    "    text = f.read()\n",
    "    \n",
    "# Viewing a portion of the original text\n",
    "text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b52ace41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T05:02:06.449799Z",
     "iopub.status.busy": "2021-12-23T05:02:06.449010Z",
     "iopub.status.idle": "2021-12-23T05:02:06.461358Z",
     "shell.execute_reply": "2021-12-23T05:02:06.460910Z",
     "shell.execute_reply.started": "2021-12-23T04:51:12.286049Z"
    },
    "papermill": {
     "duration": 0.023256,
     "end_time": "2021-12-23T05:02:06.461475",
     "exception": false,
     "start_time": "2021-12-23T05:02:06.438219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'अब गाह्रो छैन प्रदूषण नाप्न भारतीय पूर्व प्रधानमन्त्रीलाई उपप्रधानमन्त्री निधीले किन भेटे लाठी लिएका हजारौँ संख्यामा रहेका थारुहरुले र्याली प्रर्दशन गरी राजापुर बजारको दक्षिण चौकमा कोणसभा गरेका थिए आफूहरुले आफनो स्वाभिमानको लडाइ लडेको उनको भनाई थियो प्रदर्शनकारीले प्रहरी दमन बन्द गर, कैलाली कञ्चनपुर छाड्दैनौँ , प्रतिगमनकारी होसियार जस्ता नारा लगाएका थिए भारतको अघोषित नाकाबन्दीका कारण पेट्रोलियम पदार्थको अभाव भएपछि सर्वसाधारणले जोखिमपूर्ण यात्रा गर्नुपर्ने बाध्यता बढेको छ पेट्रोलियम पदार्थ पाउन छ'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some basic preprocessing\n",
    "\n",
    "text = \" \".join(text.split()) # Remove any remaining white spaces\n",
    "text = text.replace('\"', '').replace(\"'\", '') # Remove single and double quotation marks\n",
    "\n",
    "# Viewing a portion of the preprocessed text\n",
    "text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf2bd5fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T05:02:06.537472Z",
     "iopub.status.busy": "2021-12-23T05:02:06.536134Z",
     "iopub.status.idle": "2021-12-23T05:02:06.552035Z",
     "shell.execute_reply": "2021-12-23T05:02:06.552545Z",
     "shell.execute_reply.started": "2021-12-23T04:51:12.764256Z"
    },
    "papermill": {
     "duration": 0.082092,
     "end_time": "2021-12-23T05:02:06.552696",
     "exception": false,
     "start_time": "2021-12-23T05:02:06.470604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique words: 10648\n",
      "\n",
      "Word Count: [('अब', 34), ('गाह्रो', 4), ('छैन', 11), ('प्रदूषण', 1), ('नाप्न', 1)]\n",
      "\n",
      "Document Count: 1\n",
      "\n",
      "Word Index: {'छ': 1, 'र': 2, 'भएको': 3, 'पनि': 4, 'गरेको': 5}\n"
     ]
    }
   ],
   "source": [
    "# Apply Tokenization\n",
    "\n",
    "# Fitting tokenizer on text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "\n",
    "# View what the tokenizer has learned\n",
    "vocab_size = len(tokenizer.word_index)+1\n",
    "print(f'Total number of unique words: {vocab_size}\\n')\n",
    "print(f\"Word Count: {list(tokenizer.word_counts.items())[:5]}\\n\")\n",
    "print(f\"Document Count: {tokenizer.document_count}\\n\")\n",
    "print(f\"Word Index: {dict(list(tokenizer.word_index.items())[:5])}\")\n",
    "\n",
    "# Saving the tokenizer\n",
    "pickle.dump(tokenizer, open(\"./tokenizer_nepali.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3612f08a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T05:02:06.611449Z",
     "iopub.status.busy": "2021-12-23T05:02:06.576010Z",
     "iopub.status.idle": "2021-12-23T05:02:06.613830Z",
     "shell.execute_reply": "2021-12-23T05:02:06.614553Z",
     "shell.execute_reply.started": "2021-12-23T04:51:13.805380Z"
    },
    "papermill": {
     "duration": 0.052032,
     "end_time": "2021-12-23T05:02:06.614719",
     "exception": false,
     "start_time": "2021-12-23T05:02:06.562687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of sequence data: 32863\n",
      "[89, 1184, 404, 3736, 3737]\n"
     ]
    }
   ],
   "source": [
    "# Transforming text to sequences\n",
    "sequence_data = tokenizer.texts_to_sequences([text])[0]\n",
    "print(f'Length of sequence data: {len(sequence_data)}')\n",
    "print(sequence_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6434fbb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T05:02:06.713189Z",
     "iopub.status.busy": "2021-12-23T05:02:06.712432Z",
     "iopub.status.idle": "2021-12-23T05:02:06.716237Z",
     "shell.execute_reply": "2021-12-23T05:02:06.716630Z",
     "shell.execute_reply.started": "2021-12-23T04:51:16.619801Z"
    },
    "papermill": {
     "duration": 0.091952,
     "end_time": "2021-12-23T05:02:06.716756",
     "exception": false,
     "start_time": "2021-12-23T05:02:06.624804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sequences: 32860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  89, 1184,  404, 3736],\n",
       "       [1184,  404, 3736, 3737],\n",
       "       [ 404, 3736, 3737,  118],\n",
       "       [3736, 3737,  118,  405],\n",
       "       [3737,  118,  405, 1556]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating sequences each having 4 words (first three words are used to predict the fourth word)\n",
    "sequences = []\n",
    "\n",
    "for i in range(3, len(sequence_data)):\n",
    "    words = sequence_data[i-3:i+1]\n",
    "    sequences.append(words)\n",
    "\n",
    "sequences = np.array(sequences)\n",
    "print(f'Total number of sequences: {sequences.shape[0]}')\n",
    "sequences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bca884db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T05:02:06.742770Z",
     "iopub.status.busy": "2021-12-23T05:02:06.741844Z",
     "iopub.status.idle": "2021-12-23T05:02:06.812158Z",
     "shell.execute_reply": "2021-12-23T05:02:06.812579Z",
     "shell.execute_reply.started": "2021-12-23T04:51:23.954949Z"
    },
    "papermill": {
     "duration": 0.085796,
     "end_time": "2021-12-23T05:02:06.812726",
     "exception": false,
     "start_time": "2021-12-23T05:02:06.726930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking first 3 words as input and last word as output\n",
    "\n",
    "X = sequences[:,0:3]\n",
    "y = sequences[:,3]\n",
    "\n",
    "# Converting output into binary class matrix\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81a89f36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T05:02:06.839104Z",
     "iopub.status.busy": "2021-12-23T05:02:06.838557Z",
     "iopub.status.idle": "2021-12-23T05:02:09.683758Z",
     "shell.execute_reply": "2021-12-23T05:02:09.684546Z",
     "shell.execute_reply.started": "2021-12-23T04:52:02.805695Z"
    },
    "papermill": {
     "duration": 2.861299,
     "end_time": "2021-12-23T05:02:09.684711",
     "exception": false,
     "start_time": "2021-12-23T05:02:06.823412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 3, 10)             106480    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 3, 256)            273408    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10648)             1373592   \n",
      "=================================================================\n",
      "Total params: 2,311,688\n",
      "Trainable params: 2,311,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating a LSTM model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=3))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23a27f3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T05:02:09.720388Z",
     "iopub.status.busy": "2021-12-23T05:02:09.719488Z",
     "iopub.status.idle": "2021-12-23T05:02:09.725636Z",
     "shell.execute_reply": "2021-12-23T05:02:09.725191Z",
     "shell.execute_reply.started": "2021-12-23T04:54:59.667674Z"
    },
    "papermill": {
     "duration": 0.028633,
     "end_time": "2021-12-23T05:02:09.725754",
     "exception": false,
     "start_time": "2021-12-23T05:02:09.697121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training the model\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./model.h5\", monitor=\"loss\", verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "reduce = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=3, min_lr=0.0001, verbose = 1)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=Adam(learning_rate=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a1c84d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T05:02:09.753182Z",
     "iopub.status.busy": "2021-12-23T05:02:09.752476Z",
     "iopub.status.idle": "2021-12-23T05:10:15.988526Z",
     "shell.execute_reply": "2021-12-23T05:10:15.988919Z",
     "shell.execute_reply.started": "2021-12-23T04:56:55.908851Z"
    },
    "papermill": {
     "duration": 486.252072,
     "end_time": "2021-12-23T05:10:15.989151",
     "exception": false,
     "start_time": "2021-12-23T05:02:09.737079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "411/411 [==============================] - 9s 10ms/step - loss: 8.5376 - val_loss: 8.4494\n",
      "\n",
      "Epoch 00001: loss improved from inf to 8.53763, saving model to ./model.h5\n",
      "Epoch 2/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 8.0304 - val_loss: 8.6942\n",
      "\n",
      "Epoch 00002: loss improved from 8.53763 to 8.03041, saving model to ./model.h5\n",
      "Epoch 3/150\n",
      "411/411 [==============================] - 4s 9ms/step - loss: 7.8405 - val_loss: 8.9505\n",
      "\n",
      "Epoch 00003: loss improved from 8.03041 to 7.84049, saving model to ./model.h5\n",
      "Epoch 4/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 7.5874 - val_loss: 9.1827\n",
      "\n",
      "Epoch 00004: loss improved from 7.84049 to 7.58739, saving model to ./model.h5\n",
      "Epoch 5/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 7.3478 - val_loss: 9.5348\n",
      "\n",
      "Epoch 00005: loss improved from 7.58739 to 7.34780, saving model to ./model.h5\n",
      "Epoch 6/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 7.1171 - val_loss: 9.8655\n",
      "\n",
      "Epoch 00006: loss improved from 7.34780 to 7.11710, saving model to ./model.h5\n",
      "Epoch 7/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 6.8799 - val_loss: 10.3647\n",
      "\n",
      "Epoch 00007: loss improved from 7.11710 to 6.87990, saving model to ./model.h5\n",
      "Epoch 8/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 6.6426 - val_loss: 10.6241\n",
      "\n",
      "Epoch 00008: loss improved from 6.87990 to 6.64263, saving model to ./model.h5\n",
      "Epoch 9/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 6.3929 - val_loss: 11.4247\n",
      "\n",
      "Epoch 00009: loss improved from 6.64263 to 6.39289, saving model to ./model.h5\n",
      "Epoch 10/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 6.1364 - val_loss: 12.0108\n",
      "\n",
      "Epoch 00010: loss improved from 6.39289 to 6.13642, saving model to ./model.h5\n",
      "Epoch 11/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 5.8422 - val_loss: 12.9600\n",
      "\n",
      "Epoch 00011: loss improved from 6.13642 to 5.84219, saving model to ./model.h5\n",
      "Epoch 12/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 5.5226 - val_loss: 13.7893\n",
      "\n",
      "Epoch 00012: loss improved from 5.84219 to 5.52264, saving model to ./model.h5\n",
      "Epoch 13/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 5.1929 - val_loss: 15.2213\n",
      "\n",
      "Epoch 00013: loss improved from 5.52264 to 5.19292, saving model to ./model.h5\n",
      "Epoch 14/150\n",
      "411/411 [==============================] - 4s 9ms/step - loss: 4.8658 - val_loss: 16.1886\n",
      "\n",
      "Epoch 00014: loss improved from 5.19292 to 4.86580, saving model to ./model.h5\n",
      "Epoch 15/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 4.5658 - val_loss: 17.3486\n",
      "\n",
      "Epoch 00015: loss improved from 4.86580 to 4.56580, saving model to ./model.h5\n",
      "Epoch 16/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 4.2859 - val_loss: 19.2389\n",
      "\n",
      "Epoch 00016: loss improved from 4.56580 to 4.28591, saving model to ./model.h5\n",
      "Epoch 17/150\n",
      "411/411 [==============================] - 4s 9ms/step - loss: 4.0135 - val_loss: 20.2293\n",
      "\n",
      "Epoch 00017: loss improved from 4.28591 to 4.01354, saving model to ./model.h5\n",
      "Epoch 18/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 3.7601 - val_loss: 21.1138\n",
      "\n",
      "Epoch 00018: loss improved from 4.01354 to 3.76009, saving model to ./model.h5\n",
      "Epoch 19/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 3.5380 - val_loss: 22.5689\n",
      "\n",
      "Epoch 00019: loss improved from 3.76009 to 3.53795, saving model to ./model.h5\n",
      "Epoch 20/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 3.3271 - val_loss: 23.6174\n",
      "\n",
      "Epoch 00020: loss improved from 3.53795 to 3.32707, saving model to ./model.h5\n",
      "Epoch 21/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 3.1317 - val_loss: 25.1840\n",
      "\n",
      "Epoch 00021: loss improved from 3.32707 to 3.13172, saving model to ./model.h5\n",
      "Epoch 22/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 2.9534 - val_loss: 25.8789\n",
      "\n",
      "Epoch 00022: loss improved from 3.13172 to 2.95340, saving model to ./model.h5\n",
      "Epoch 23/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 2.7938 - val_loss: 26.7129\n",
      "\n",
      "Epoch 00023: loss improved from 2.95340 to 2.79381, saving model to ./model.h5\n",
      "Epoch 24/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 2.6585 - val_loss: 28.1424\n",
      "\n",
      "Epoch 00024: loss improved from 2.79381 to 2.65847, saving model to ./model.h5\n",
      "Epoch 25/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 2.5216 - val_loss: 29.0079\n",
      "\n",
      "Epoch 00025: loss improved from 2.65847 to 2.52157, saving model to ./model.h5\n",
      "Epoch 26/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 2.4013 - val_loss: 29.4389\n",
      "\n",
      "Epoch 00026: loss improved from 2.52157 to 2.40134, saving model to ./model.h5\n",
      "Epoch 27/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 2.2863 - val_loss: 30.7163\n",
      "\n",
      "Epoch 00027: loss improved from 2.40134 to 2.28634, saving model to ./model.h5\n",
      "Epoch 28/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 2.1897 - val_loss: 30.8473\n",
      "\n",
      "Epoch 00028: loss improved from 2.28634 to 2.18971, saving model to ./model.h5\n",
      "Epoch 29/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 2.0810 - val_loss: 31.5665\n",
      "\n",
      "Epoch 00029: loss improved from 2.18971 to 2.08098, saving model to ./model.h5\n",
      "Epoch 30/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 1.9893 - val_loss: 32.2645\n",
      "\n",
      "Epoch 00030: loss improved from 2.08098 to 1.98931, saving model to ./model.h5\n",
      "Epoch 31/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 1.9216 - val_loss: 33.0377\n",
      "\n",
      "Epoch 00031: loss improved from 1.98931 to 1.92160, saving model to ./model.h5\n",
      "Epoch 32/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 1.8310 - val_loss: 33.1449\n",
      "\n",
      "Epoch 00032: loss improved from 1.92160 to 1.83104, saving model to ./model.h5\n",
      "Epoch 33/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 1.7435 - val_loss: 33.9628\n",
      "\n",
      "Epoch 00033: loss improved from 1.83104 to 1.74354, saving model to ./model.h5\n",
      "Epoch 34/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 1.6834 - val_loss: 34.7460\n",
      "\n",
      "Epoch 00034: loss improved from 1.74354 to 1.68339, saving model to ./model.h5\n",
      "Epoch 35/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 1.6096 - val_loss: 35.3685\n",
      "\n",
      "Epoch 00035: loss improved from 1.68339 to 1.60959, saving model to ./model.h5\n",
      "Epoch 36/150\n",
      "411/411 [==============================] - 3s 9ms/step - loss: 1.5389 - val_loss: 36.1288\n",
      "\n",
      "Epoch 00036: loss improved from 1.60959 to 1.53885, saving model to ./model.h5\n",
      "Epoch 37/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 1.4805 - val_loss: 36.2070\n",
      "\n",
      "Epoch 00037: loss improved from 1.53885 to 1.48047, saving model to ./model.h5\n",
      "Epoch 38/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 1.4305 - val_loss: 36.5902\n",
      "\n",
      "Epoch 00038: loss improved from 1.48047 to 1.43047, saving model to ./model.h5\n",
      "Epoch 39/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 1.3823 - val_loss: 37.0103\n",
      "\n",
      "Epoch 00039: loss improved from 1.43047 to 1.38227, saving model to ./model.h5\n",
      "Epoch 40/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 1.3271 - val_loss: 37.7930\n",
      "\n",
      "Epoch 00040: loss improved from 1.38227 to 1.32715, saving model to ./model.h5\n",
      "Epoch 41/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 1.2750 - val_loss: 38.6769\n",
      "\n",
      "Epoch 00041: loss improved from 1.32715 to 1.27497, saving model to ./model.h5\n",
      "Epoch 42/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 1.2340 - val_loss: 37.7434\n",
      "\n",
      "Epoch 00042: loss improved from 1.27497 to 1.23400, saving model to ./model.h5\n",
      "Epoch 43/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 1.2118 - val_loss: 38.6026\n",
      "\n",
      "Epoch 00043: loss improved from 1.23400 to 1.21181, saving model to ./model.h5\n",
      "Epoch 44/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 1.1530 - val_loss: 39.3893\n",
      "\n",
      "Epoch 00044: loss improved from 1.21181 to 1.15297, saving model to ./model.h5\n",
      "Epoch 45/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 1.1184 - val_loss: 40.0137\n",
      "\n",
      "Epoch 00045: loss improved from 1.15297 to 1.11844, saving model to ./model.h5\n",
      "Epoch 46/150\n",
      "411/411 [==============================] - 4s 9ms/step - loss: 1.0662 - val_loss: 39.1885\n",
      "\n",
      "Epoch 00046: loss improved from 1.11844 to 1.06623, saving model to ./model.h5\n",
      "Epoch 47/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 1.0369 - val_loss: 40.4211\n",
      "\n",
      "Epoch 00047: loss improved from 1.06623 to 1.03692, saving model to ./model.h5\n",
      "Epoch 48/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 1.0155 - val_loss: 40.1932\n",
      "\n",
      "Epoch 00048: loss improved from 1.03692 to 1.01546, saving model to ./model.h5\n",
      "Epoch 49/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.9709 - val_loss: 40.9210\n",
      "\n",
      "Epoch 00049: loss improved from 1.01546 to 0.97095, saving model to ./model.h5\n",
      "Epoch 50/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.9465 - val_loss: 41.4565\n",
      "\n",
      "Epoch 00050: loss improved from 0.97095 to 0.94646, saving model to ./model.h5\n",
      "Epoch 51/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.9133 - val_loss: 41.8238\n",
      "\n",
      "Epoch 00051: loss improved from 0.94646 to 0.91334, saving model to ./model.h5\n",
      "Epoch 52/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.9059 - val_loss: 41.5403\n",
      "\n",
      "Epoch 00052: loss improved from 0.91334 to 0.90595, saving model to ./model.h5\n",
      "Epoch 53/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.8696 - val_loss: 41.9648\n",
      "\n",
      "Epoch 00053: loss improved from 0.90595 to 0.86959, saving model to ./model.h5\n",
      "Epoch 54/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.8536 - val_loss: 41.7363\n",
      "\n",
      "Epoch 00054: loss improved from 0.86959 to 0.85361, saving model to ./model.h5\n",
      "Epoch 55/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.8093 - val_loss: 43.1197\n",
      "\n",
      "Epoch 00055: loss improved from 0.85361 to 0.80933, saving model to ./model.h5\n",
      "Epoch 56/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.7914 - val_loss: 42.7968\n",
      "\n",
      "Epoch 00056: loss improved from 0.80933 to 0.79141, saving model to ./model.h5\n",
      "Epoch 57/150\n",
      "411/411 [==============================] - 4s 9ms/step - loss: 0.7777 - val_loss: 43.2666\n",
      "\n",
      "Epoch 00057: loss improved from 0.79141 to 0.77766, saving model to ./model.h5\n",
      "Epoch 58/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.7506 - val_loss: 43.0667\n",
      "\n",
      "Epoch 00058: loss improved from 0.77766 to 0.75061, saving model to ./model.h5\n",
      "Epoch 59/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.7399 - val_loss: 43.4115\n",
      "\n",
      "Epoch 00059: loss improved from 0.75061 to 0.73986, saving model to ./model.h5\n",
      "Epoch 60/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.7087 - val_loss: 43.9318\n",
      "\n",
      "Epoch 00060: loss improved from 0.73986 to 0.70872, saving model to ./model.h5\n",
      "Epoch 61/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.6895 - val_loss: 44.2050\n",
      "\n",
      "Epoch 00061: loss improved from 0.70872 to 0.68954, saving model to ./model.h5\n",
      "Epoch 62/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.6749 - val_loss: 44.7471\n",
      "\n",
      "Epoch 00062: loss improved from 0.68954 to 0.67485, saving model to ./model.h5\n",
      "Epoch 63/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.6728 - val_loss: 44.5361\n",
      "\n",
      "Epoch 00063: loss improved from 0.67485 to 0.67282, saving model to ./model.h5\n",
      "Epoch 64/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.6465 - val_loss: 44.8987\n",
      "\n",
      "Epoch 00064: loss improved from 0.67282 to 0.64653, saving model to ./model.h5\n",
      "Epoch 65/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.6277 - val_loss: 45.7934\n",
      "\n",
      "Epoch 00065: loss improved from 0.64653 to 0.62766, saving model to ./model.h5\n",
      "Epoch 66/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.6157 - val_loss: 44.7652\n",
      "\n",
      "Epoch 00066: loss improved from 0.62766 to 0.61567, saving model to ./model.h5\n",
      "Epoch 67/150\n",
      "411/411 [==============================] - 4s 10ms/step - loss: 0.5912 - val_loss: 45.7141\n",
      "\n",
      "Epoch 00067: loss improved from 0.61567 to 0.59122, saving model to ./model.h5\n",
      "Epoch 68/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.5881 - val_loss: 45.6014\n",
      "\n",
      "Epoch 00068: loss improved from 0.59122 to 0.58807, saving model to ./model.h5\n",
      "Epoch 69/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.5715 - val_loss: 45.7436\n",
      "\n",
      "Epoch 00069: loss improved from 0.58807 to 0.57145, saving model to ./model.h5\n",
      "Epoch 70/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.5688 - val_loss: 45.8250\n",
      "\n",
      "Epoch 00070: loss improved from 0.57145 to 0.56881, saving model to ./model.h5\n",
      "Epoch 71/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.5565 - val_loss: 46.2773\n",
      "\n",
      "Epoch 00071: loss improved from 0.56881 to 0.55648, saving model to ./model.h5\n",
      "Epoch 72/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.5280 - val_loss: 46.0480\n",
      "\n",
      "Epoch 00072: loss improved from 0.55648 to 0.52797, saving model to ./model.h5\n",
      "Epoch 73/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.5166 - val_loss: 46.3698\n",
      "\n",
      "Epoch 00073: loss improved from 0.52797 to 0.51659, saving model to ./model.h5\n",
      "Epoch 74/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.5078 - val_loss: 47.0396\n",
      "\n",
      "Epoch 00074: loss improved from 0.51659 to 0.50778, saving model to ./model.h5\n",
      "Epoch 75/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.5015 - val_loss: 47.2048\n",
      "\n",
      "Epoch 00075: loss improved from 0.50778 to 0.50151, saving model to ./model.h5\n",
      "Epoch 76/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.5009 - val_loss: 46.7662\n",
      "\n",
      "Epoch 00076: loss improved from 0.50151 to 0.50087, saving model to ./model.h5\n",
      "Epoch 77/150\n",
      "411/411 [==============================] - 4s 10ms/step - loss: 0.4816 - val_loss: 47.5754\n",
      "\n",
      "Epoch 00077: loss improved from 0.50087 to 0.48160, saving model to ./model.h5\n",
      "Epoch 78/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.4759 - val_loss: 47.3885\n",
      "\n",
      "Epoch 00078: loss improved from 0.48160 to 0.47587, saving model to ./model.h5\n",
      "Epoch 79/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.4530 - val_loss: 48.0452\n",
      "\n",
      "Epoch 00079: loss improved from 0.47587 to 0.45298, saving model to ./model.h5\n",
      "Epoch 80/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.4467 - val_loss: 48.4378\n",
      "\n",
      "Epoch 00080: loss improved from 0.45298 to 0.44666, saving model to ./model.h5\n",
      "Epoch 81/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.4502 - val_loss: 48.3609\n",
      "\n",
      "Epoch 00081: loss did not improve from 0.44666\n",
      "Epoch 82/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.4378 - val_loss: 48.5615\n",
      "\n",
      "Epoch 00082: loss improved from 0.44666 to 0.43780, saving model to ./model.h5\n",
      "Epoch 83/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.4262 - val_loss: 47.9182\n",
      "\n",
      "Epoch 00083: loss improved from 0.43780 to 0.42619, saving model to ./model.h5\n",
      "Epoch 84/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.4194 - val_loss: 48.5131\n",
      "\n",
      "Epoch 00084: loss improved from 0.42619 to 0.41937, saving model to ./model.h5\n",
      "Epoch 85/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.4080 - val_loss: 48.6492\n",
      "\n",
      "Epoch 00085: loss improved from 0.41937 to 0.40797, saving model to ./model.h5\n",
      "Epoch 86/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.4234 - val_loss: 48.5319\n",
      "\n",
      "Epoch 00086: loss did not improve from 0.40797\n",
      "Epoch 87/150\n",
      "411/411 [==============================] - 4s 9ms/step - loss: 0.4044 - val_loss: 49.1297\n",
      "\n",
      "Epoch 00087: loss improved from 0.40797 to 0.40437, saving model to ./model.h5\n",
      "Epoch 88/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.3988 - val_loss: 48.6843\n",
      "\n",
      "Epoch 00088: loss improved from 0.40437 to 0.39881, saving model to ./model.h5\n",
      "Epoch 89/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.3866 - val_loss: 48.9054\n",
      "\n",
      "Epoch 00089: loss improved from 0.39881 to 0.38661, saving model to ./model.h5\n",
      "Epoch 90/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.3732 - val_loss: 48.4926\n",
      "\n",
      "Epoch 00090: loss improved from 0.38661 to 0.37318, saving model to ./model.h5\n",
      "Epoch 91/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.3816 - val_loss: 49.2519\n",
      "\n",
      "Epoch 00091: loss did not improve from 0.37318\n",
      "Epoch 92/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.3742 - val_loss: 49.7690\n",
      "\n",
      "Epoch 00092: loss did not improve from 0.37318\n",
      "Epoch 93/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.3718 - val_loss: 48.8848\n",
      "\n",
      "Epoch 00093: loss improved from 0.37318 to 0.37176, saving model to ./model.h5\n",
      "Epoch 94/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.3603 - val_loss: 49.3011\n",
      "\n",
      "Epoch 00094: loss improved from 0.37176 to 0.36027, saving model to ./model.h5\n",
      "Epoch 95/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.3513 - val_loss: 49.2888\n",
      "\n",
      "Epoch 00095: loss improved from 0.36027 to 0.35135, saving model to ./model.h5\n",
      "Epoch 96/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.3420 - val_loss: 49.4383\n",
      "\n",
      "Epoch 00096: loss improved from 0.35135 to 0.34200, saving model to ./model.h5\n",
      "Epoch 97/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.3364 - val_loss: 49.2188\n",
      "\n",
      "Epoch 00097: loss improved from 0.34200 to 0.33642, saving model to ./model.h5\n",
      "Epoch 98/150\n",
      "411/411 [==============================] - 4s 10ms/step - loss: 0.3335 - val_loss: 49.7020\n",
      "\n",
      "Epoch 00098: loss improved from 0.33642 to 0.33350, saving model to ./model.h5\n",
      "Epoch 99/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.3284 - val_loss: 50.0478\n",
      "\n",
      "Epoch 00099: loss improved from 0.33350 to 0.32839, saving model to ./model.h5\n",
      "Epoch 100/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.3234 - val_loss: 50.1571\n",
      "\n",
      "Epoch 00100: loss improved from 0.32839 to 0.32342, saving model to ./model.h5\n",
      "Epoch 101/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.3256 - val_loss: 50.4310\n",
      "\n",
      "Epoch 00101: loss did not improve from 0.32342\n",
      "Epoch 102/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.3328 - val_loss: 50.6830\n",
      "\n",
      "Epoch 00102: loss did not improve from 0.32342\n",
      "Epoch 103/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.3145 - val_loss: 51.1505\n",
      "\n",
      "Epoch 00103: loss improved from 0.32342 to 0.31447, saving model to ./model.h5\n",
      "Epoch 104/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.3126 - val_loss: 50.3710\n",
      "\n",
      "Epoch 00104: loss improved from 0.31447 to 0.31256, saving model to ./model.h5\n",
      "Epoch 105/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.3001 - val_loss: 50.3562\n",
      "\n",
      "Epoch 00105: loss improved from 0.31256 to 0.30005, saving model to ./model.h5\n",
      "Epoch 106/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.3094 - val_loss: 51.0517\n",
      "\n",
      "Epoch 00106: loss did not improve from 0.30005\n",
      "Epoch 107/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.2872 - val_loss: 50.7050\n",
      "\n",
      "Epoch 00107: loss improved from 0.30005 to 0.28717, saving model to ./model.h5\n",
      "Epoch 108/150\n",
      "411/411 [==============================] - 4s 9ms/step - loss: 0.2951 - val_loss: 50.1713\n",
      "\n",
      "Epoch 00108: loss did not improve from 0.28717\n",
      "Epoch 109/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.2885 - val_loss: 50.5883\n",
      "\n",
      "Epoch 00109: loss did not improve from 0.28717\n",
      "Epoch 110/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.2866 - val_loss: 50.5460\n",
      "\n",
      "Epoch 00110: loss improved from 0.28717 to 0.28660, saving model to ./model.h5\n",
      "Epoch 111/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.2814 - val_loss: 50.2003\n",
      "\n",
      "Epoch 00111: loss improved from 0.28660 to 0.28144, saving model to ./model.h5\n",
      "Epoch 112/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.2826 - val_loss: 50.4625\n",
      "\n",
      "Epoch 00112: loss did not improve from 0.28144\n",
      "Epoch 113/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.2879 - val_loss: 50.4513\n",
      "\n",
      "Epoch 00113: loss did not improve from 0.28144\n",
      "Epoch 114/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.2803 - val_loss: 50.5886\n",
      "\n",
      "Epoch 00114: loss improved from 0.28144 to 0.28030, saving model to ./model.h5\n",
      "Epoch 115/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.2691 - val_loss: 50.6213\n",
      "\n",
      "Epoch 00115: loss improved from 0.28030 to 0.26913, saving model to ./model.h5\n",
      "Epoch 116/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.2520 - val_loss: 51.1948\n",
      "\n",
      "Epoch 00116: loss improved from 0.26913 to 0.25196, saving model to ./model.h5\n",
      "Epoch 117/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.2534 - val_loss: 51.6583\n",
      "\n",
      "Epoch 00117: loss did not improve from 0.25196\n",
      "Epoch 118/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.2543 - val_loss: 51.3555\n",
      "\n",
      "Epoch 00118: loss did not improve from 0.25196\n",
      "Epoch 119/150\n",
      "411/411 [==============================] - 4s 10ms/step - loss: 0.2582 - val_loss: 51.3213\n",
      "\n",
      "Epoch 00119: loss did not improve from 0.25196\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 120/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.1748 - val_loss: 51.8474\n",
      "\n",
      "Epoch 00120: loss improved from 0.25196 to 0.17478, saving model to ./model.h5\n",
      "Epoch 121/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.1253 - val_loss: 52.6953\n",
      "\n",
      "Epoch 00121: loss improved from 0.17478 to 0.12533, saving model to ./model.h5\n",
      "Epoch 122/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.1112 - val_loss: 53.0057\n",
      "\n",
      "Epoch 00122: loss improved from 0.12533 to 0.11119, saving model to ./model.h5\n",
      "Epoch 123/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.1010 - val_loss: 53.4401\n",
      "\n",
      "Epoch 00123: loss improved from 0.11119 to 0.10104, saving model to ./model.h5\n",
      "Epoch 124/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.1007 - val_loss: 53.5735\n",
      "\n",
      "Epoch 00124: loss improved from 0.10104 to 0.10067, saving model to ./model.h5\n",
      "Epoch 125/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.0948 - val_loss: 54.2094\n",
      "\n",
      "Epoch 00125: loss improved from 0.10067 to 0.09480, saving model to ./model.h5\n",
      "Epoch 126/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.0888 - val_loss: 54.1754\n",
      "\n",
      "Epoch 00126: loss improved from 0.09480 to 0.08877, saving model to ./model.h5\n",
      "Epoch 127/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.0880 - val_loss: 54.5524\n",
      "\n",
      "Epoch 00127: loss improved from 0.08877 to 0.08796, saving model to ./model.h5\n",
      "Epoch 128/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.0868 - val_loss: 54.9655\n",
      "\n",
      "Epoch 00128: loss improved from 0.08796 to 0.08681, saving model to ./model.h5\n",
      "Epoch 129/150\n",
      "411/411 [==============================] - 4s 9ms/step - loss: 0.0866 - val_loss: 54.9198\n",
      "\n",
      "Epoch 00129: loss improved from 0.08681 to 0.08658, saving model to ./model.h5\n",
      "Epoch 130/150\n",
      "411/411 [==============================] - 4s 9ms/step - loss: 0.0831 - val_loss: 55.1422\n",
      "\n",
      "Epoch 00130: loss improved from 0.08658 to 0.08315, saving model to ./model.h5\n",
      "Epoch 131/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.0839 - val_loss: 55.3336\n",
      "\n",
      "Epoch 00131: loss did not improve from 0.08315\n",
      "Epoch 132/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.0839 - val_loss: 55.5701\n",
      "\n",
      "Epoch 00132: loss did not improve from 0.08315\n",
      "Epoch 133/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.0816 - val_loss: 55.4600\n",
      "\n",
      "Epoch 00133: loss improved from 0.08315 to 0.08164, saving model to ./model.h5\n",
      "Epoch 134/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.0844 - val_loss: 55.7968\n",
      "\n",
      "Epoch 00134: loss did not improve from 0.08164\n",
      "Epoch 135/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.0791 - val_loss: 55.4909\n",
      "\n",
      "Epoch 00135: loss improved from 0.08164 to 0.07911, saving model to ./model.h5\n",
      "Epoch 136/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.0792 - val_loss: 55.5524\n",
      "\n",
      "Epoch 00136: loss did not improve from 0.07911\n",
      "Epoch 137/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.0800 - val_loss: 55.5579\n",
      "\n",
      "Epoch 00137: loss did not improve from 0.07911\n",
      "Epoch 138/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.0754 - val_loss: 55.9690\n",
      "\n",
      "Epoch 00138: loss improved from 0.07911 to 0.07539, saving model to ./model.h5\n",
      "Epoch 139/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.0773 - val_loss: 56.2283\n",
      "\n",
      "Epoch 00139: loss did not improve from 0.07539\n",
      "Epoch 140/150\n",
      "411/411 [==============================] - 4s 9ms/step - loss: 0.0760 - val_loss: 56.1537\n",
      "\n",
      "Epoch 00140: loss did not improve from 0.07539\n",
      "Epoch 141/150\n",
      "411/411 [==============================] - 4s 9ms/step - loss: 0.0738 - val_loss: 56.3053\n",
      "\n",
      "Epoch 00141: loss improved from 0.07539 to 0.07379, saving model to ./model.h5\n",
      "Epoch 142/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.0717 - val_loss: 56.4381\n",
      "\n",
      "Epoch 00142: loss improved from 0.07379 to 0.07174, saving model to ./model.h5\n",
      "Epoch 143/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.0749 - val_loss: 56.0497\n",
      "\n",
      "Epoch 00143: loss did not improve from 0.07174\n",
      "Epoch 144/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.0731 - val_loss: 56.5546\n",
      "\n",
      "Epoch 00144: loss did not improve from 0.07174\n",
      "Epoch 145/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.0728 - val_loss: 56.5307\n",
      "\n",
      "Epoch 00145: loss did not improve from 0.07174\n",
      "\n",
      "Epoch 00145: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 146/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.0646 - val_loss: 56.5957\n",
      "\n",
      "Epoch 00146: loss improved from 0.07174 to 0.06456, saving model to ./model.h5\n",
      "Epoch 147/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.0602 - val_loss: 56.9613\n",
      "\n",
      "Epoch 00147: loss improved from 0.06456 to 0.06024, saving model to ./model.h5\n",
      "Epoch 148/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.0627 - val_loss: 57.0643\n",
      "\n",
      "Epoch 00148: loss did not improve from 0.06024\n",
      "Epoch 149/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.0618 - val_loss: 57.1568\n",
      "\n",
      "Epoch 00149: loss did not improve from 0.06024\n",
      "Epoch 150/150\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.0623 - val_loss: 56.9648\n",
      "\n",
      "Epoch 00150: loss did not improve from 0.06024\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X,\n",
    "          y,\n",
    "          epochs=150,\n",
    "          batch_size=64,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[checkpoint, reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4164762e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T05:10:20.359551Z",
     "iopub.status.busy": "2021-12-23T05:10:20.358680Z",
     "iopub.status.idle": "2021-12-23T05:10:20.594491Z",
     "shell.execute_reply": "2021-12-23T05:10:20.593876Z",
     "shell.execute_reply.started": "2021-12-23T04:59:12.581056Z"
    },
    "papermill": {
     "duration": 2.320796,
     "end_time": "2021-12-23T05:10:20.594640",
     "exception": false,
     "start_time": "2021-12-23T05:10:18.273844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting losses and accuracies on each epochs\n",
    "\n",
    "# loss\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('LossVal_loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 514.293977,
   "end_time": "2021-12-23T05:10:26.262699",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-23T05:01:51.968722",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
